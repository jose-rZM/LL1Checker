#include <boost/spirit/include/lex_lexertl.hpp>
#include <vector>
class lexer {
    std::string              filename_;
    std::vector<std::string> tokens_;
    unsigned                 current_;

  public:
    /**
     * @brief Lexer functor for defining tokenization rules using Boost Spirit
     * Lex.
     *
     * This struct is a functor that defines the tokenization rules for the
     * lexer. It inherits from `boost::spirit::lex::lexer<Lexer>` and is used to
     * configure the lexer with regular expressions and corresponding token IDs.
     * The rules are added to the lexer during construction.
     *
     * @tparam Lexer The type of lexer to be used (e.g.,
     * `boost::spirit::lex::lexertl::lexer<>`).
     *
     * @details The constructor performs the following steps:
     * 1. Iterates over the token types defined in
     * `symbol_table::token_types_r_`.
     * 2. Adds regular expressions and their corresponding token IDs to the
     * lexer.
     * 3. Skips whitespace characters (spaces, tabs, and newlines) by assigning
     * them a specific token ID.
     *
     * @see symbol_table::token_types_r_
     * @see symbol_table::st_
     */
    template <typename Lexer>
    struct parse_input : boost::spirit::lex::lexer<Lexer> {
        parse_input();
    };

    /**
     * @brief Functor for adding tokens to the token list during tokenization.
     *
     * This struct is a functor that processes tokens generated by the lexer and
     * adds them to a list of tokens (`tks`). It is used as a callback during
     * the tokenization process.
     *
     * @details The `operator()` method performs the following steps:
     * 1. Checks if the token ID matches a special token (e.g., whitespace) that
     * should be ignored.
     * 2. If the token is not ignored, adds the corresponding token type (from
     * `symbol_table::token_types_r_`) to the token list.
     *
     * @see symbol_table::token_types_r_
     */
    struct add {
        typedef bool result_type;
        template <typename Token>
        bool operator()(Token const& t, std::vector<std::string>& tks) const;
    };
    /**
     * @brief Constructs a lexer and tokenizes the specified input file.
     *
     * @param filename Path to the input file containing the string to be
     * validated.
     *
     * @note The program aborts if any errors occur during lexer creation or
     * tokenization.
     */
    explicit lexer(std::string filename);

    /**
     * @brief Retrieves the next token from the token vector.
     *
     * @return std::string The next token in the sequence; returns an empty
     * string if the end of the line (EOL) is reached.
     *
     * This function allows sequential access to tokens processed by the lexer.
     */
    std::string next();

  private:
    /**
     * @brief Tokenizes the input file using Boost Spirit Lex.
     *
     * This function reads the content of the file specified by `filename_`,
     * tokenizes it using Boost Spirit Lex, and stores the resulting tokens in
     * the `tokens_` member variable. If the tokenization process encounters an
     * invalid token, a `LexerError` is thrown with an error message indicating
     * the invalid token.
     *
     * @throws LexerError If an invalid token is encountered during
     * tokenization.
     *
     * @details The function performs the following steps:
     * 1. Opens the file specified by `filename_` and reads its content into a
     * string.
     * 2. Converts the string into a C-style string (char array) for processing.
     * 3. Uses Boost Spirit Lex to tokenize the input string.
     * 4. If tokenization is successful, the tokens are stored in the `tokens_`
     * member variable.
     * 5. If tokenization fails (e.g., due to an invalid token), a `LexerError`
     * is thrown.
     *
     * @note The function relies on the `parse_input` functor and the `add`
     * function to handle the tokenization and token storage, respectively.
     *
     * @see LexerError
     * @see tokens_
     * @see filename_
     */
    void tokenize();
};
